# Advanced Tape Restorer v4.1

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Platform: Windows](https://img.shields.io/badge/platform-Windows-blue.svg)](https://www.microsoft.com/windows)
[![GitHub release](https://img.shields.io/github/v/release/idocinthebox/Advanced-Tape-Restorer)](https://github.com/idocinthebox/Advanced-Tape-Restorer/releases)

**Professional Video Restoration & Capture Suite with AI Enhancement**

Advanced Tape Restorer is a powerful desktop application for capturing and restoring analog/DV tapes to high-quality digital video. Features professional-grade VapourSynth filtering, AI-powered upscaling/deinterlacing, NPU acceleration, and checkpoint-based resumable processing for multi-hour jobs.

---

## üìã Table of Contents

- [‚ú® Key Features](#-key-features)
- [üì¶ Installation](#-installation)
- [üöÄ Quick Start Guide](#-quick-start-guide)
- [ü§ñ AI Models](#-ai-models)
- [‚öôÔ∏è Technical Architecture](#Ô∏è-technical-architecture)
- [üé¨ Usage Examples](#-usage-examples)
- [üó∫Ô∏è Roadmap](#Ô∏è-roadmap)
- [ü§ù Contributing](#-contributing)
- [üìÑ License](#-license)
- [üôè Acknowledgments](#-acknowledgments)

---

## üéØ Project Vision

Version 2.0 represents a complete architectural redesign with clear separation of concerns:
- **Core Processing**: Independent video restoration engine
- **Capture Module**: Professional tape capture capabilities
- **GUI Layer**: Modern PySide6 interface
- **Modular Design**: Each component can be modified without affecting others

## üìÅ Project Structure

```
Advanced Tape Restorer v4.1/
‚îú‚îÄ‚îÄ core/                      # Video processing engine (independent)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ processor.py          # Main orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ video_analyzer.py     # Metadata & field order detection
‚îÇ   ‚îú‚îÄ‚îÄ vapoursynth_engine.py # VapourSynth script generation
‚îÇ   ‚îî‚îÄ‚îÄ ffmpeg_encoder.py     # FFmpeg encoding with progress
‚îÇ
‚îú‚îÄ‚îÄ capture/                   # Video capture module (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ device_manager.py     # Device detection & management
‚îÇ   ‚îú‚îÄ‚îÄ analog_capture.py     # Analog/VHS capture engine
‚îÇ   ‚îî‚îÄ‚îÄ dv_capture.py         # DV/miniDV FireWire capture
‚îÇ
‚îú‚îÄ‚îÄ gui/                       # PySide6 GUI (to be created)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main_window.py        # Main application window
‚îÇ   ‚îú‚îÄ‚îÄ restoration_tab.py    # Restoration controls
‚îÇ   ‚îú‚îÄ‚îÄ capture_tab.py        # Capture interface (NEW)
‚îÇ   ‚îî‚îÄ‚îÄ dialogs/              # Preset manager, batch queue, etc.
‚îÇ
‚îú‚îÄ‚îÄ config/                    # Configuration & settings
‚îÇ   ‚îî‚îÄ‚îÄ default_settings.json
‚îÇ
‚îî‚îÄ‚îÄ docs/                      # Documentation
    ‚îú‚îÄ‚îÄ API.md                # API reference for modules
    ‚îú‚îÄ‚îÄ CAPTURE_GUIDE.md      # Capture workflow documentation
    ‚îî‚îÄ‚îÄ ARCHITECTURE.md       # Technical architecture details
```

## ‚ú® Key Features

### üé• Video Restoration
- **Professional deinterlacing** - QTGMC with 7 quality presets (Draft ‚Üí Placebo)
- **AI upscaling** - RealESRGAN, BasicVSR++, SwinIR (SD‚ÜíHD/4K)
- **AI interpolation** - RIFE frame rate boosting (2x-4x)
- **AI restoration** - GFPGAN face enhancement, DeOldify colorization, ProPainter inpainting
- **Advanced filtering** - BM3D denoising, VHS artifact removal, chroma restoration
- **Smart field order detection** - Automatic TFF/BFF/Progressive analysis
- **NPU acceleration** - ONNX inference with DirectML (40x faster, 98% smaller models)
- **Multi-GPU support** - Heterogeneous workload distribution (NVIDIA + AMD + Intel)

### üìº Tape Capture (NEW in v4.0)
- **Analog capture** - VHS, Hi8, Video8, Betamax support via DirectShow
- **DV/FireWire capture** - miniDV, HDV with stream copy
- **Device detection** - Automatic capture card discovery
- **Input selection** - Composite, S-Video, Component

### üí™ Reliability & Performance
- **Checkpoint system** - Auto-save every 50-100 frames, resume after crashes (NEW in v4.0)
- **Disk space protection** - Pre-flight checks, 508GB exhaustion prevention (NEW in v4.0)
- **Frame migration** - Automatic drive switching for multi-TB projects (NEW in v4.0)
- **PyTorch JIT compilation** - 20-30% AI performance boost (NEW in v4.0)
- **Threaded I/O** - Parallel disk operations eliminate bottlenecks (NEW in v4.0)

### üéõÔ∏è User Experience
- **Live preview** - See results before processing
- **Batch processing** - Queue multiple restoration jobs
- **Preset system** - Save/load restoration configurations
- **Progress tracking** - Real-time ETA and frame-by-frame status
- **Multiple codecs** - ProRes, DNxHD, H.264/H.265/AV1, lossless options

## ‚öôÔ∏è Technical Architecture

### Processing Pipeline

```
Input Video ‚Üí VapourSynth Filters ‚Üí FFmpeg Encoder ‚Üí Output Video
    ‚Üì
  .vpy script (generated dynamically)
    ‚Üì
  vspipe.exe (external process)
    ‚Üì
  YUV frames (piped)
    ‚Üì
  ffmpeg.exe (encoding)
```

**Key Design:** VapourSynth runs as separate process, cannot import from PyInstaller EXE

### Modular Structure

```
core/                      # Video processing engine
‚îú‚îÄ‚îÄ processor.py          # Main orchestrator (vspipe ‚Üí ffmpeg)
‚îú‚îÄ‚îÄ vapoursynth_engine.py # .vpy script generation
‚îú‚îÄ‚îÄ ffmpeg_encoder.py     # Encoding with progress tracking
‚îú‚îÄ‚îÄ ai_bridge.py          # AI model integration
‚îú‚îÄ‚îÄ disk_space_manager.py # Pre-flight space checks (NEW v4.0)
‚îú‚îÄ‚îÄ resumable_processor.py # Checkpoint base class (NEW v4.0)
‚îú‚îÄ‚îÄ gfpgan_checkpoint_processor.py # GFPGAN with checkpoints (NEW v4.0)
‚îú‚îÄ‚îÄ propainter_checkpoint_processor.py # ProPainter checkpoints (NEW v4.0)
‚îú‚îÄ‚îÄ torch_jit_optimizer.py # PyTorch compilation (NEW v4.0)
‚îú‚îÄ‚îÄ threaded_io.py        # Async file operations (NEW v4.0)
‚îú‚îÄ‚îÄ multi_gpu_manager.py  # GPU detection & distribution (NEW v4.0)
‚îî‚îÄ‚îÄ onnx_converter.py     # ONNX model conversion (NEW v4.1)

capture/                   # Hardware capture (NEW v4.0)
‚îú‚îÄ‚îÄ device_manager.py     # DirectShow device detection
‚îú‚îÄ‚îÄ analog_capture.py     # Analog capture via FFmpeg
‚îî‚îÄ‚îÄ dv_capture.py         # DV/FireWire capture

gui/                       # PySide6 interface
‚îú‚îÄ‚îÄ main_window.py        # Main UI (3 tabs: Restoration/Capture/Batch)
‚îú‚îÄ‚îÄ processing_thread.py  # Background worker with Qt signals
‚îú‚îÄ‚îÄ checkpoint_resume_dialog.py # Resume incomplete jobs (NEW v4.0)
‚îî‚îÄ‚îÄ settings_manager.py   # JSON-based settings persistence

ai_models/                 # AI model system
‚îú‚îÄ‚îÄ model_manager.py      # Download, verify, cache models
‚îú‚îÄ‚îÄ engines/              # Per-engine implementations
‚îÇ   ‚îú‚îÄ‚îÄ realesrgan.py
‚îÇ   ‚îú‚îÄ‚îÄ rife.py
‚îÇ   ‚îú‚îÄ‚îÄ basicvsrpp.py
‚îÇ   ‚îî‚îÄ‚îÄ ... (11 engines total)
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ registry.yaml     # URLs, SHA256, licenses
```

### Threading Model

- **Main thread:** PySide6 GUI event loop
- **Worker thread:** Video processing (`ProcessingThread` class)
- **Monitor threads:** Capture status, live preview
- **Communication:** Qt signals/slots (thread-safe)

### Data Flow

1. User selects options in GUI
2. Options saved to `restoration_settings.json`
3. `ProcessingThread` calls `VideoProcessor.process_video()`
4. VapourSynth script generated to `%TEMP%\tape_restorer_XXXXX.vpy`
5. `vspipe.exe` spawned as subprocess, pipes YUV frames
6. `ffmpeg.exe` spawned as subprocess, encodes piped frames
7. Progress parsed from FFmpeg stderr, emitted via Qt signal
8. GUI updates progress bar, ETA, log window

### Checkpoint System (v4.0)

**Architecture:**
- `ResumableProcessor` base class - Generic checkpoint save/load/resume logic
- `GFPGANCheckpointProcessor` wrapper - Frame-level checkpoints for GFPGAN
- `ProPainterCheckpointProcessor` wrapper - Process-level checkpoints for ProPainter
- Checkpoints stored: `%LOCALAPPDATA%\Advanced_Tape_Restorer\checkpoints\`
- Resume detection: `QTimer.singleShot(1000)` on startup shows dialog

**Frame Migration:**
- Detects output directory change between checkpoint and resume
- Automatically copies all frames/files from old drive to new drive
- Uses `shutil.copy2()` with progress logging every 100 items
- Ensures FFmpeg reads all frames from single consolidated directory

## ÔøΩ Installation

### Prerequisites

**Required:**
- **Windows 10/11** (64-bit)
- **FFmpeg 6.0+** - Video encoding and metadata extraction
  - Download: https://ffmpeg.org/download.html
  - Add to PATH: `ffmpeg.exe`, `ffprobe.exe`
- **VapourSynth R65+** (R73 recommended) - Video processing framework
  - Download: https://github.com/vapoursynth/vapoursynth/releases
  - Add to PATH: `vspipe.exe`
- **Python 3.8-3.12** - Runtime environment

**Optional (for AI features):**
- **CUDA 11.8/12.1** - GPU acceleration for AI models
- **DirectML** - NPU/GPU acceleration for ONNX inference (NEW in v4.1)
- **vs-realesrgan** - VapourSynth plugin (`vsrepo install realesrgan`)
- **vs-rife** - Frame interpolation plugin (`vsrepo install rife`)

### Quick Start

1. **Download latest release** from GitHub Releases
2. **Extract** `Advanced_Tape_Restorer_v4.1.zip`
3. **Double-click** `Advanced_Tape_Restorer_v4.1.exe`
4. **First launch** will check prerequisites and extract AI models

### Installation Scripts (Optional)

The `UTILITIES/` folder contains setup helpers:
- `Install_FFmpeg.bat` - Automated FFmpeg installation
- `Install_VapourSynth.bat` - VapourSynth setup with plugins
- `Install_ONNX_Runtime_NPU.bat` - NPU acceleration setup (NEW in v4.1)
- `Install_PyTorch_CUDA.bat` - GPU acceleration setup

### Development Setup

```powershell
# Clone repository
git clone https://github.com/idocinthebox/Advanced-Tape-Restorer.git
cd Advanced-Tape-Restorer

# Create virtual environment
python -m venv .venv
.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Run from source
python main.py
```

## üöÄ Quick Start Guide

### Basic Restoration Workflow

1. **Load video** - Click "Browse" and select your captured tape file
2. **Select preset** - Choose quality level (Fast/Balanced/Quality/Maximum)
3. **Configure options**:
   - **Deinterlacing**: QTGMC preset (Slow/Very Slow for best quality)
   - **Upscaling**: Enable AI upscaling if going SD‚ÜíHD/4K
   - **Denoising**: BM3D for tape noise removal
4. **Preview** - Click "Preview" to test settings on short clip
5. **Process** - Click "Start Processing" and monitor progress
6. **Resume support** - If interrupted, restart app and click "Resume" in startup dialog

### Capture Workflow (NEW in v4.0)

1. **Connect capture device** - Elgato, Diamond VC500, AVerMedia, etc.
2. **Switch to Capture tab**
3. **Select device** - Choose from detected analog/DV devices
4. **Choose input** - Composite (RCA), S-Video, or Component
5. **Set codec** - HuffYUV/FFV1 for lossless, H.264 for compressed
6. **Start capture** - Click "Start Capture" and play your tape

### Checkpoint System (NEW in v4.0)

For long processing jobs (2-15 hours):

- **Automatic saving** - Checkpoints every 50 frames (GFPGAN) or on completion (ProPainter)
- **Resume on startup** - If job incomplete, app shows resume dialog
- **Drive switching** - Can change temp directory mid-job, frames auto-migrate
- **Disk space monitoring** - Pre-flight checks prevent 508GB exhaustion

**Configuration:**
- Settings ‚Üí Performance & Cache ‚Üí GFPGAN/ProPainter Temp Directory
- Browse to select alternative drive (D:\, E:\, etc.)
- System automatically migrates existing frames/files

## ü§ñ AI Models

Advanced Tape Restorer supports 11 AI enhancement engines:

| Model | Purpose | Size | Speed | Quality |
|-------|---------|------|-------|---------|
| **RealESRGAN** | 4x upscaling | 64MB | Fast (GPU) | Excellent |
| **BasicVSR++** | 2x video upscaling | 37MB | Medium | Excellent |
| **SwinIR** | 2-4x upscaling | 48MB | Medium | Excellent |
| **RIFE** | Frame interpolation | 17MB | Fast (GPU) | Excellent |
| **GFPGAN** | Face restoration | 350MB | Slow | Very Good |
| **DeOldify** | Colorization | 120MB | Medium | Good |
| **ProPainter** | Video inpainting | 280MB | Very Slow | Excellent |
| **ZNEDI3** | Fast 2x upscaling | Built-in | Very Fast | Good |

### ONNX/NPU Acceleration (NEW in v4.1)

**98% model compression** with DirectML acceleration:
- RealESRGAN: 3.82MB ‚Üí 0.16MB (40x faster)
- RIFE: 2.11MB ‚Üí 0.01MB
- BasicVSR++: 2.69MB ‚Üí 0.01MB
- SwinIR: 2.13MB ‚Üí 0.01MB

**Benefits:**
- ‚úÖ 40x faster inference (2.5ms vs 100ms per frame)
- ‚úÖ Offloads 6-8GB from GPU VRAM to NPU
- ‚úÖ Enables 4K AI processing on 8GB GPUs
- ‚úÖ Hybrid GPU+NPU pipeline

**Setup:** Run `UTILITIES/Install_ONNX_Runtime_NPU.bat`

### Model Downloads

Models are automatically downloaded on first use. Manual installation:

```python
from ai_models import ModelManager

manager = ModelManager()
manager.download_model("realesrgan")  # Downloads and verifies SHA256
```

**Registry:** `ai_models/models/registry.yaml` contains all model URLs, hashes, licenses

### Licensing

Each AI model has its own license. See `ai_models/models/registry.yaml` for details:
- RealESRGAN: BSD 3-Clause
- GFPGAN: Non-commercial research use
- DeOldify: MIT
- ProPainter: Research/academic use

‚ö†Ô∏è **Users must comply with individual model licenses when using AI features.**

## üé¨ Usage Examples

### Example 1: Basic VHS Restoration
```python
from core import VideoProcessor

processor = VideoProcessor()

options = {
    'field_order': 'Top Field First (TFF)',  # Analog standard
    'qtgmc_preset': 'Slow',                  # High-quality deinterlacing
    'denoise_strength': 'Medium (Slow)',     # Remove tape noise
    'use_vhs_cleanup': True,                 # TComb + chroma fixes
    'codec': 'libx264 (H.264, CPU)',
    'crf': '18',                             # Near-lossless
    'ffmpeg_preset': 'slow'
}

processor.process_video(
    "vhs_capture.avi",
    "restored.mp4",
    options,
    progress_callback=lambda pct, eta: print(f"{pct:.1f}% - ETA: {eta}"),
    log_callback=print
)
```

### Example 2: AI Upscaling SD‚ÜíHD
```python
options = {
    'field_order': 'Auto-Detect',
    'qtgmc_preset': 'Slow',
    'use_ai_upscaling': True,
    'ai_upscale_method': 'RealESRGAN',       # 4x upscaling
    'ai_upscale_inference': 'onnx',          # NPU acceleration (v4.1)
    'target_resolution': '1920x1080',
    'codec': 'prores_ks (ProRes 422 HQ)',    # High-quality codec
}

processor.process_video("sd_video.avi", "hd_output.mov", options)
```

### Example 3: Face Restoration with Checkpoints
```python
from core.gfpgan_checkpoint_processor import process_gfpgan_with_checkpoints

# Long-running job with automatic checkpoints every 50 frames
process_gfpgan_with_checkpoints(
    input_video="family_tape.avi",
    output_video="enhanced.mp4",
    options={
        'face_upsample': 2,              # 2x face resolution
        'gfpgan_temp_dir': 'D:/GFPGAN',  # Use D:\ for 508GB frames
        'codec': 'libx264 (H.264, CPU)',
        'crf': '18'
    },
    progress_callback=lambda pct, eta: print(f"{pct:.1f}%"),
    log_callback=print
)

# If interrupted, restart app ‚Üí Resume dialog appears automatically
```

### Example 4: Capture Then Process
```python
from capture import CaptureDeviceManager, AnalogCaptureEngine
from capture.analog_capture import AnalogCaptureSettings

# Step 1: Capture from VHS
manager = CaptureDeviceManager()
devices = manager.get_analog_devices()

settings = AnalogCaptureSettings(
    device_name=devices[0].path,
    resolution="720x480",
    framerate="29.97",
    codec="huffyuv",           # Lossless
    video_input="Composite"    # Or S-Video, Component
)

capture_engine = AnalogCaptureEngine()
capture_engine.start_capture(settings, "D:/captured.avi")

# ... wait for tape to finish ...

# Step 2: Process captured video
processor = VideoProcessor()
processor.process_video("D:/captured.avi", "D:/restored.mp4", restoration_options)
```

### Example 5: Batch Processing with Multi-GPU
```python
from core import VideoProcessor
from core.multi_gpu_manager import MultiGPUManager

# Detect available GPUs
gpu_manager = MultiGPUManager()
ai_gpu = gpu_manager.get_best_ai_gpu()        # NVIDIA RTX for AI
encode_gpu = gpu_manager.get_best_encode_gpu() # AMD for encoding

print(f"AI GPU: {ai_gpu.name} ({ai_gpu.vram_gb}GB)")
print(f"Encode GPU: {encode_gpu.name}")

# Process multiple files
files = ["tape1.avi", "tape2.avi", "tape3.avi"]
for input_file in files:
    output = input_file.replace(".avi", "_restored.mp4")
    
    options = {
        'use_ai_upscaling': True,
        'ai_gpu_index': ai_gpu.index,      # Use NVIDIA for AI
        'encoder_gpu': encode_gpu.vendor,   # Use AMD for encoding
        'codec': 'h264_amf (H.264, AMD)',
    }
    
    processor.process_video(input_file, output, options)
```

## ÔøΩÔ∏è Roadmap

### v4.0 - Capture & Reliability (‚úÖ Complete - December 2025)
- [x] DirectShow capture device detection
- [x] Analog capture engine (Composite/S-Video/Component)
- [x] DV/FireWire capture support
- [x] Checkpoint/resume system for long jobs
- [x] Disk space protection (508GB exhaustion prevention)
- [x] Frame migration for drive switching
- [x] PyTorch JIT compilation (20-30% speedup)
- [x] Threaded I/O operations
- [x] Multi-GPU support (NVIDIA + AMD + Intel)

### v4.1 - NPU Acceleration (‚úÖ Complete - December 2025)
- [x] ONNX model converter with FP16/INT8 quantization
- [x] DirectML runtime integration (NPU + GPU + CPU)
- [x] 98% model compression (3.82MB ‚Üí 0.16MB)
- [x] 40x inference speedup (2.5ms vs 100ms per frame)
- [x] Hybrid GPU+NPU processing pipeline
- [x] GUI inference mode selection (Auto/PyTorch/TorchScript/ONNX)

### v4.2 - User Experience (Q1 2026)
- [ ] Enhanced capture preview with waveform monitor
- [ ] Real-time dropped frame monitoring
- [ ] DV timecode extraction and display
- [ ] Scene detection during capture
- [ ] Automatic tape format detection (VHS/Hi8/DV)
- [ ] Project file format for multi-tape archives

### v4.3 - Advanced Processing (Q2 2026)
- [ ] Temporal denoising with motion compensation
- [ ] HDR tone mapping for modern displays
- [ ] Dolby Vision/HDR10+ metadata generation
- [ ] VBI/teletext decoding for European tapes
- [ ] Adaptive quality zones (faces/action get more bitrate)

### v5.0 Pro - Network Rendering (Commercial - Q3-Q4 2026)
- [ ] Distributed processing across 5-10 machines
- [ ] REST API + WebSocket architecture
- [ ] Worker discovery and load balancing
- [ ] Fault tolerance and automatic recovery
- [ ] Render farm support for studios
- [ ] Subscription licensing per render node

See [ROADMAP_v4.0.md](ROADMAP_v4.0.md) for complete technical details.

## ü§ù Contributing

Contributions are welcome! This project uses modular architecture for easy contribution:

### Areas for Contribution

1. **Core Processing** - Enhance restoration filters, optimize performance
2. **AI Models** - Add new upscaling/restoration engines
3. **Capture Hardware** - Add support for additional capture devices
4. **GUI/UX** - Improve interface, add features
5. **Documentation** - Tutorials, guides, translations

### Development Setup

```powershell
# Fork and clone
git clone https://github.com/idocinthebox/Advanced-Tape-Restorer.git
cd Advanced-Tape-Restorer

# Create feature branch
git checkout -b feature/your-feature-name

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python main.py --test

# Make changes and test
python main.py

# Commit with descriptive message
git commit -m "Add feature: description"

# Push and create pull request
git push origin feature/your-feature-name
```

### Code Style

- **Python**: PEP 8 formatting
- **Docstrings**: Google style
- **Type hints**: Use where applicable
- **Comments**: Explain "why", not "what"
- **Testing**: Add tests for new features

### Pull Request Guidelines

1. **Clear description** - What problem does it solve?
2. **Test results** - Include test output or screenshots
3. **Breaking changes** - Document any API changes
4. **Performance** - Note any speed improvements/regressions
5. **Dependencies** - List any new requirements

### Reporting Issues

Use GitHub Issues for:
- üêõ **Bug reports** - Include logs, error messages, system info
- üí° **Feature requests** - Describe use case and expected behavior
- üìù **Documentation** - Unclear instructions, missing info
- ‚ùì **Questions** - General usage questions

**Template for bug reports:**
```markdown
**System Info:**
- OS: Windows 10/11
- Python version: 3.x
- FFmpeg version: x.x
- VapourSynth version: Rxx

**Steps to reproduce:**
1. Load video file X
2. Enable option Y
3. Click Start Processing

**Expected:** Should process successfully
**Actual:** Error message: "..."

**Logs:** (paste relevant log output)
```

## üìÑ License

MIT License - See [LICENSE](LICENSE) file for details

Copyright (c) 2025 Advanced Tape Restorer Contributors

### Third-Party Licenses

This project uses the following open-source software:

- **FFmpeg** - LGPL 2.1+ / GPL 2+ (depending on build)
- **VapourSynth** - LGPL 2.1
- **PyTorch** - BSD 3-Clause
- **PySide6** - LGPL 3.0
- **QTGMC** - GPL 2.0
- **BM3D** - GPL 3.0

### AI Model Licenses

AI models are separately licensed by their authors:

- **RealESRGAN** - BSD 3-Clause (Commercial use allowed)
- **GFPGAN** - Non-commercial research use only
- **BasicVSR++** - Apache 2.0
- **SwinIR** - Apache 2.0
- **RIFE** - MIT License
- **DeOldify** - MIT License
- **ProPainter** - Research/academic use (check license)

‚ö†Ô∏è **Important:** Users must comply with individual AI model licenses. Some models (GFPGAN, ProPainter) may restrict commercial use. Check `ai_models/models/registry.yaml` for complete license details.

### Commercial Licensing

## License Structure Overview

**Version 4.1 and earlier** components of Advanced Tape Restorer are released under the **MIT License** and remain permanently licensed under those terms.

**Beginning with version 4.2**, newly developed features, modules, and binaries are proprietary and licensed under a commercial End User License Agreement (EULA) issued by [Your Company Name, LLC].

This licensing structure ensures open access to foundational components while protecting advanced professional features developed in later versions.

### MIT-Licensed Components (v4.1 and earlier)

The following components are licensed under the MIT License:

- Core processing modules released as part of v4.1 or earlier
- Associated utilities explicitly marked as MIT in their source headers

These components may be freely used, modified, forked, and redistributed in accordance with the MIT License. No additional restrictions apply.

### Proprietary Components (v4.2 and later)

All features introduced in version 4.2 or later are proprietary and require a valid commercial license. This includes audio restoration modules, project management tools, frame stabilization, scene detection, advanced UI themes, cross-platform builds, and professional workflow tools.

**Redistribution, sublicensing, resale, or public hosting of these proprietary components or binaries is strictly prohibited without written authorization.**

### Commercial Licensing Options

**v4.2 Early Supporter Edition:**
- $45 one-time (limited to first 500 supporters)
- Lifetime v4.2 updates + community support
- Single-user license

**v4.2 Standard Edition:**
- $150 one-time
- 1 year priority support (then $75/year to renew or use community support)
- Single-user license

**v5.0+ Pro/Enterprise:**
- Subscription-based for distributed rendering
- See [VERSION_FEATURE_MATRIX.md](VERSION_FEATURE_MATRIX.md) for details

**License Grant:** Each commercial license is granted to a **single individual user**. A license may not be shared, transferred, or used concurrently by multiple individuals. Installation on multiple devices owned by the same licensed user is permitted, provided the software is not used simultaneously by more than one person.

For complete licensing details, see:
- [LICENSE_V4.2.txt](LICENSE_V4.2.txt) - Full EULA
- [LICENSING_GUIDE.md](LICENSING_GUIDE.md) - User-friendly guide
- [LICENSE](LICENSE) - v4.1 MIT License

For commercial inquiries: [Contact information to be added]

## üôè Acknowledgments

Built on 4+ years of development and production testing.

### Core Technologies

- **[VapourSynth](https://www.vapoursynth.com/)** - Professional video processing framework
- **[FFmpeg](https://ffmpeg.org/)** - Universal video encoding and transcoding
- **[QTGMC](http://avisynth.nl/index.php/QTGMC)** - World-class motion-adaptive deinterlacing
- **[PySide6](https://doc.qt.io/qtforpython/)** - Qt6 Python bindings for modern GUI

### AI/ML Frameworks

- **[PyTorch](https://pytorch.org/)** - Deep learning framework
- **[ONNX Runtime](https://onnxruntime.ai/)** - Cross-platform ML inference
- **[DirectML](https://github.com/microsoft/DirectML)** - NPU/GPU acceleration on Windows

### VapourSynth Filters

- **[BM3D](https://github.com/HomeOfVapourSynthEvolution/VapourSynth-BM3D)** - Advanced denoising
- **[TComb](https://github.com/dubhater/vapoursynth-tcomb)** - VHS artifact removal
- **[Bifrost](https://github.com/dubhater/vapoursynth-bifrost)** - Chroma restoration
- **[ZNEDI3](https://github.com/sekrit-twc/znedi3)** - Fast neural deinterlacing
- **[havsfunc](https://github.com/HomeOfVapourSynthEvolution/havsfunc)** - Essential filter collection

### AI Model Authors

- **RealESRGAN** - Xintao Wang et al., Tencent ARC Lab
- **GFPGAN** - Xintao Wang et al., Tencent ARC Lab
- **BasicVSR++** - Kelvin C.K. Chan et al., CUHK & SenseTime
- **SwinIR** - Jingyun Liang et al., ETH Zurich
- **RIFE** - Zhewei Huang et al., MEGVII Technology
- **DeOldify** - Jason Antic
- **ProPainter** - Shangchen Zhou et al., S-Lab

### Community

Special thanks to the VapourSynth and video preservation communities for their invaluable knowledge sharing and tool development.

### Development History

- **v1.0-2.0** (2021-2023) - Initial development with Gemini Pro assistance
- **v3.0-3.3** (2024) - AI model integration, architecture refinement
- **v4.0** (December 2025) - Real capture hardware, checkpoint system, multi-GPU support
- **v4.1** (December 2025) - ONNX/NPU acceleration, model compression

See [CHANGES_FOR_CLAUDE.TXT](CHANGES_FOR_CLAUDE.TXT) and [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) for complete development history.

---

## üìû Support & Community

- **GitHub Issues**: Bug reports and feature requests
- **Discussions**: Questions and community support
- **Documentation**: [docs/](docs/) folder for detailed guides
- **Wiki**: (Coming soon) User tutorials and examples

## üåü Star History

If this project helps you preserve your family memories or professional archives, please consider giving it a ‚≠ê on GitHub!

---

**Version**: 4.1.0  
**Status**: Production Ready  
**Last Updated**: December 28, 2025  
**License**: MIT

Made with ‚ù§Ô∏è for the video preservation community
